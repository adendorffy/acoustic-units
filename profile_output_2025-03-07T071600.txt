Timer unit: 1e-09 s

Total time: 0.291344 s
File: /Users/daneladendorff/Desktop/adendorffy/acoustic-units/dist.py
Function: get_features_and_filenames at line 38

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    38                                           @profile
    39                                           def get_features_and_filenames(sorted_paths):
    40         1       1000.0   1000.0      0.0      filenames = []
    41         1          0.0      0.0      0.0      features = []
    42      1001   11206000.0  11194.8      3.8      for path in tqdm(sorted_paths, desc="Appending Features"):
    43      1000    2065000.0   2065.0      0.7          filenames.append(path.stem)
    44      1000  277924000.0 277924.0     95.4          feature = np.load(path)
    45      1000     148000.0    148.0      0.1          features.append(feature)
    46         1          0.0      0.0      0.0      return features, filenames

Total time: 22.8134 s
File: /Users/daneladendorff/Desktop/adendorffy/acoustic-units/dist.py
Function: main at line 49

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    49                                           @profile
    50                                           def main():
    51                                               # Process chunks
    52         1          0.0      0.0      0.0      gamma = 0.1
    53         1 1316716000.0    1e+09      5.8      paths = list(Path(f"features/{gamma}").rglob("*.npy"))
    54                                           
    55         1   93694000.0    9e+07      0.4      sorted_paths = sorted(paths, key=lambda x: int(x.stem.split("_")[-1]))
    56         1     245000.0 245000.0      0.0      sorted_paths = sorted_paths[0:1000]
    57         1          0.0      0.0      0.0      sample_size = len(sorted_paths)
    58                                           
    59         1  291973000.0    3e+08      1.3      features, filenames = get_features_and_filenames(sorted_paths)
    60                                           
    61         1          0.0      0.0      0.0      chunk_limit = 5000000
    62         1       2000.0   2000.0      0.0      num_pairs = sample_size * (sample_size - 1) // 2
    63         1          0.0      0.0      0.0      num_chunks = (num_pairs + chunk_limit - 1) // chunk_limit
    64                                           
    65         1       1000.0   1000.0      0.0      row_indices = []
    66         1          0.0      0.0      0.0      col_indices = []
    67         1          0.0      0.0      0.0      values = []
    68                                           
    69         1       8000.0   8000.0      0.0      print(f"num_pairs: {num_pairs}")
    70         1       3000.0   3000.0      0.0      print(f"num_chunks: {num_chunks}")
    71         1       2000.0   2000.0      0.0      print(f"num_samples: {sample_size}")
    72                                           
    73                                               # Preallocate sparse matrix in LIL format (efficient for incremental additions)
    74         1     369000.0 369000.0      0.0      dist_sparse = sp.lil_matrix((sample_size, sample_size), dtype=np.float32)
    75                                           
    76                                               # Process Chunks Efficiently
    77         3  203404000.0    7e+07      0.9      for chunk in tqdm(
    78         1       2000.0   2000.0      0.0          get_batch_of_paths(sample_size, chunk_limit=chunk_limit),
    79         1          0.0      0.0      0.0          total=num_chunks,
    80         1          0.0      0.0      0.0          desc="Processing Chunks",
    81         1          0.0      0.0      0.0          unit="chunk",
    82                                               ):
    83                                                   # Avoid unnecessary dictionary wrapping
    84    499501  162986000.0    326.3      0.7          chunk_units = [((i, j), (features[i], features[j])) for i, j in chunk]
    85                                           
    86         2   24041000.0    1e+07      0.1          with Pool(6) as pool:
    87    499501        2e+10  36117.7     79.1              for i, j, dist in pool.imap_unordered(cal_dist_per_pair, chunk_units):
    88    499500 1295460000.0   2593.5      5.7                  dist_sparse[i, j] = dist  # Fill the sparse matrix
    89    499500 1224551000.0   2451.6      5.4                  dist_sparse[j, i] = dist  # Symmetric distance
    90                                           
    91                                               # Convert to a compressed sparse format for efficient storage
    92         1   41051000.0    4e+07      0.2      dist_sparse = dist_sparse.tocoo()
    93         1  118085000.0    1e+08      0.5      np.savez_compressed("output/test/sparse_dist_mat.npz", dist_sparse)

  0.29 seconds - /Users/daneladendorff/Desktop/adendorffy/acoustic-units/dist.py:38 - get_features_and_filenames
 22.81 seconds - /Users/daneladendorff/Desktop/adendorffy/acoustic-units/dist.py:49 - main
