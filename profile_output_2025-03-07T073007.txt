Timer unit: 1e-09 s

Total time: 0.846791 s
File: /Users/daneladendorff/Desktop/adendorffy/acoustic-units/dist.py
Function: get_features_and_filenames at line 38

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    38                                           @profile
    39                                           def get_features_and_filenames(sorted_paths):
    40         1          0.0      0.0      0.0      filenames = []
    41         1          0.0      0.0      0.0      features = []
    42      3001   13097000.0   4364.2      1.5      for path in tqdm(sorted_paths, desc="Appending Features"):
    43      3000    6207000.0   2069.0      0.7          filenames.append(path.stem)
    44      3000  827148000.0 275716.0     97.7          feature = np.load(path)
    45      3000     338000.0    112.7      0.0          features.append(feature)
    46         1       1000.0   1000.0      0.0      return features, filenames

Total time: 197.476 s
File: /Users/daneladendorff/Desktop/adendorffy/acoustic-units/dist.py
Function: main at line 49

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    49                                           @profile
    50                                           def main():
    51                                               # Process chunks
    52         1       1000.0   1000.0      0.0      gamma = 0.1
    53         1 1266603000.0    1e+09      0.6      paths = list(Path(f"features/{gamma}").rglob("*.npy"))
    54                                           
    55         1   91748000.0    9e+07      0.0      sorted_paths = sorted(paths, key=lambda x: int(x.stem.split("_")[-1]))
    56         1     231000.0 231000.0      0.0      sorted_paths = sorted_paths[0:3000]
    57         1       1000.0   1000.0      0.0      sample_size = len(sorted_paths)
    58                                           
    59         1  848622000.0    8e+08      0.4      features, filenames = get_features_and_filenames(sorted_paths)
    60                                           
    61         1          0.0      0.0      0.0      chunk_limit = 5000000
    62         1       3000.0   3000.0      0.0      num_pairs = sample_size * (sample_size - 1) // 2
    63         1          0.0      0.0      0.0      num_chunks = (num_pairs + chunk_limit - 1) // chunk_limit
    64                                           
    65         1      13000.0  13000.0      0.0      print(f"num_pairs: {num_pairs}")
    66         1       2000.0   2000.0      0.0      print(f"num_chunks: {num_chunks}")
    67         1       2000.0   2000.0      0.0      print(f"num_samples: {sample_size}")
    68                                           
    69                                               # Preallocate sparse matrix in LIL format (efficient for incremental additions)
    70         1     759000.0 759000.0      0.0      dist_sparse = sp.lil_matrix((sample_size, sample_size), dtype=np.float32)
    71                                           
    72                                               # Process Chunks Efficiently
    73         3 1629598000.0    5e+08      0.8      for chunk in tqdm(
    74         1       2000.0   2000.0      0.0          get_batch_of_paths(sample_size, chunk_limit=chunk_limit),
    75         1          0.0      0.0      0.0          total=num_chunks,
    76         1          0.0      0.0      0.0          desc="Processing Chunks",
    77         1       1000.0   1000.0      0.0          unit="chunk",
    78                                               ):
    79                                                   # Avoid unnecessary dictionary wrapping
    80   4498501 1709183000.0    379.9      0.9          chunk_units = [((i, j), (features[i], features[j])) for i, j in chunk]
    81                                           
    82         2   34714000.0    2e+07      0.0          with Pool(6) as pool:
    83   4498501        2e+11  36819.3     83.9              for i, j, dist in pool.imap_unordered(cal_dist_per_pair, chunk_units):
    84   4498500        1e+10   2677.5      6.1                  dist_sparse[i, j] = dist  # Fill the sparse matrix
    85   4498500        1e+10   2807.9      6.4                  dist_sparse[j, i] = dist  # Symmetric distance
    86                                           
    87                                               # Convert to a compressed sparse format for efficient storage
    88         1  560791000.0    6e+08      0.3      dist_sparse = dist_sparse.tocoo()
    89         1 1025511000.0    1e+09      0.5      np.savez_compressed("output/test/sparse_dist_mat.npz", dist_sparse)

  0.85 seconds - /Users/daneladendorff/Desktop/adendorffy/acoustic-units/dist.py:38 - get_features_and_filenames
197.48 seconds - /Users/daneladendorff/Desktop/adendorffy/acoustic-units/dist.py:49 - main
