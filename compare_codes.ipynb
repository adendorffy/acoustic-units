{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "audio_dir = Path(\"librispeech/audio\")\n",
    "audio_ext = \".flac\"\n",
    "paths = list(audio_dir.rglob(f\"**/*{audio_ext}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Model(\n",
       "  (feature_extractor): FeatureExtractor(\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): ConvLayerBlock(\n",
       "        (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "      )\n",
       "      (1-4): 4 x ConvLayerBlock(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "      )\n",
       "      (5-6): 2 x ConvLayerBlock(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (feature_projection): FeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (pos_conv_embed): ConvolutionalPositionalEmbedding(\n",
       "        (conv): ParametrizedConv1d(\n",
       "          768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x EncoderLayer(\n",
       "          (attention): SelfAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): FeedForward(\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "align_dir = Path(\"librispeech/alignments\")\n",
    "align_df = pd.read_csv(align_dir / \"alignments.csv\")\n",
    "\n",
    "model_name = \"hubert_base\"\n",
    "layer = 12\n",
    "\n",
    "\n",
    "try:\n",
    "    bundle = getattr(torchaudio.pipelines, model_name.upper())\n",
    "except AttributeError:\n",
    "    raise ValueError(f\"Invalid model name: {model_name}\")\n",
    "\n",
    "model = bundle.get_model()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_encoding(\n",
    "    encoding: torch.Tensor, word_boundaries: list[float], hop_ms: int = 20\n",
    ") -> torch.Tensor:\n",
    "    hop_size = hop_ms / 1000  # seconds per frame\n",
    "    start_frame = int(word_boundaries[0] / hop_size)\n",
    "    end_frame = int(word_boundaries[1] / hop_size)\n",
    "    return encoding[start_frame:end_frame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "def collapse_runs(seq):\n",
    "    collapsed = []\n",
    "    prev = None\n",
    "    for code in seq:\n",
    "        if code != prev:\n",
    "            collapsed.append(int(code))\n",
    "            prev = code\n",
    "    return collapsed\n",
    "\n",
    "\n",
    "def greedy_segment(sequence: np.ndarray, codebook: np.ndarray) -> np.ndarray:\n",
    "    dists = cdist(sequence, codebook)\n",
    "    frame_codes = np.argmin(dists, axis=1)\n",
    "\n",
    "    segments = []\n",
    "    prev_code = frame_codes[0]\n",
    "\n",
    "    for t in range(1, len(frame_codes)):\n",
    "        if frame_codes[t] != prev_code:\n",
    "            segments.append(int(prev_code))\n",
    "            prev_code = frame_codes[t]\n",
    "\n",
    "    segments.append(int(prev_code))\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import numba\n",
    "import numpy as np\n",
    "import scipy.spatial.distance as distance\n",
    "\n",
    "\n",
    "def segment(\n",
    "    sequence: np.ndarray, codebook: np.ndarray, gamma: float\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Group speech representations into phone-like segments.\n",
    "\n",
    "    Args:\n",
    "        sequence (NDArray): speech representations of shape (T, D) where T is the number of frames and D is the feature dimension.\n",
    "        codebook (NDArray): cluster centriods of the discrete units of shape (K, D) where K is the number of codes.\n",
    "        gamma float: Duration regularizer weight. Larger values result in a coarser segmentation.\n",
    "\n",
    "    Returns:\n",
    "        NDArray[int]: list of discrete units representing each segment sound types of shape (N,).\n",
    "        NDArray[int]: list of segment boundaries of shape (N+1,).\n",
    "    \"\"\"\n",
    "    dists = distance.cdist(sequence, codebook).astype(np.float32)\n",
    "    alpha, P = _segment(dists, gamma)\n",
    "    return _backtrack(alpha, P)\n",
    "\n",
    "\n",
    "@numba.njit()\n",
    "def _segment(dists, gamma):\n",
    "    T, K = dists.shape\n",
    "\n",
    "    alpha = np.zeros(T + 1, dtype=np.float32)\n",
    "    P = np.zeros((T + 1, 2), dtype=np.int32)\n",
    "    D = np.zeros((T, T, K), dtype=np.float32)\n",
    "\n",
    "    for t in range(T):\n",
    "        for k in range(K):\n",
    "            D[t, t, k] = dists[t, k]\n",
    "    for t in range(T):\n",
    "        for s in range(t + 1, T):\n",
    "            D[t, s, :] = D[t, s - 1, :] + dists[s, :] - gamma\n",
    "\n",
    "    for t in range(T):\n",
    "        alpha[t + 1] = np.inf\n",
    "        for s in range(t + 1):\n",
    "            k = np.argmin(D[s, t, :])\n",
    "            alpha_min = alpha[s] + D[s, t, k]\n",
    "            if alpha_min < alpha[t + 1]:\n",
    "                P[t + 1, :] = s, k\n",
    "                alpha[t + 1] = alpha_min\n",
    "    return alpha, P\n",
    "\n",
    "\n",
    "@numba.njit()\n",
    "def _backtrack(alpha, P):\n",
    "    rhs = len(alpha) - 1\n",
    "    segments = []\n",
    "    boundaries = [rhs]\n",
    "    while rhs != 0:\n",
    "        lhs, code = P[rhs, :]\n",
    "        segments.append(code)\n",
    "        boundaries.append(lhs)\n",
    "        rhs = lhs\n",
    "    segments.reverse()\n",
    "    boundaries.reverse()\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "kmeans_path = f\"models/kmeans_{model_name}_layer{layer}_k100.pkl\"\n",
    "kmeans = joblib.load(kmeans_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import editdistance\n",
    "\n",
    "\n",
    "def normalized_edit_distance(sequences):\n",
    "    pairs = list(itertools.combinations(sequences, 2))\n",
    "    if not pairs:\n",
    "        return 0.0\n",
    "\n",
    "    dists = []\n",
    "    for a, b in pairs:\n",
    "        dist = editdistance.eval(a, b)\n",
    "        norm = dist / max(len(a), len(b))\n",
    "        dists.append(norm)\n",
    "\n",
    "    return np.mean(dists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "codes = []\n",
    "labels = []\n",
    "for path in paths:\n",
    "    wav_df = align_df[align_df[\"filename\"] == path.stem]\n",
    "\n",
    "    waveform, sr_loaded = torchaudio.load(str(path))\n",
    "    if sr_loaded != 16000:\n",
    "        waveform = torchaudio.functional.resample(waveform, sr_loaded, 16000)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        features, _ = model.extract_features(waveform, num_layers=layer)\n",
    "        encoding = features[layer - 1].squeeze().cpu().numpy()\n",
    "\n",
    "    for w in range(1, max(wav_df[\"word_id\"]) + 1):\n",
    "        word_df = wav_df[wav_df[\"word_id\"] == w]\n",
    "\n",
    "        text = str(word_df[\"text\"].values[0])\n",
    "        phones = tuple(str(word_df[\"phones\"].values[0]).split(\",\"))\n",
    "        if text == \"nan\":\n",
    "            continue\n",
    "\n",
    "        start = float(word_df[\"word_start\"].values[0])\n",
    "        end = float(word_df[\"word_end\"].values[0])\n",
    "        word_encoding = cut_encoding(encoding, [start, end])\n",
    "        if len(word_encoding) == 0:\n",
    "            continue\n",
    "        word_codes = kmeans.predict(word_encoding)\n",
    "        labels.append(phones)\n",
    "\n",
    "        codes.append(segment(word_encoding, kmeans.cluster_centers_, 1.0))\n",
    "\n",
    "        if len(codes) >= 500:\n",
    "            break\n",
    "\n",
    "        if len(codes) % 100 == 0:\n",
    "            print(f\"{len(codes)}\")\n",
    "\n",
    "    if len(codes) >= 500:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def calc_edit_distance(a, b):\n",
    "    dist = editdistance.eval(a, b)\n",
    "    norm = dist / max(len(a), len(b))\n",
    "\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = []\n",
    "rows = []\n",
    "cols = []\n",
    "for i in range(len(codes)):\n",
    "    for j in range(i, len(codes)):\n",
    "        dists.append(calc_edit_distance(codes[i], codes[j]))\n",
    "        rows.append(i)\n",
    "        cols.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9538479055770988\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = np.array(rows)\n",
    "cols = np.array(cols)\n",
    "dists = np.array(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "\n",
    "g = ig.Graph()\n",
    "g.add_vertices(len(codes))\n",
    "mask = dists < 0.4\n",
    "edges = list(zip(rows[mask], cols[mask]))\n",
    "weights = dists[mask].astype(float)\n",
    "weights = np.where(weights > 0, weights, 1e-10).tolist()\n",
    "\n",
    "if edges:\n",
    "    g.add_edges(edges)\n",
    "    g.es[-len(weights) :].set_attribute_values(\"weight\", weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "import leidenalg as la\n",
    "\n",
    "partition = la.find_partition(\n",
    "    g,\n",
    "    la.CPMVertexPartition,\n",
    "    resolution_parameter=0.01,\n",
    "    weights=\"weight\",\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('DH', 'AH1') ('DH', 'AH1') ('DH', 'AH0') ('DH', 'AH0') ('DH', 'AH1') ('DH', 'AH1') ('DH', 'AH0') ('DH', 'AH1') ('DH', 'AH0') ('DH', 'EH1', 'R') ('DH', 'AH0') ('DH', 'AH0') ('DH', 'AH0') ('DH', 'AH0') ('DH', 'AH0') ('DH', 'IY0') ('DH', 'AH0') ('DH', 'AH1') ('DH', 'EH1', 'R') ('DH', 'IY0') ('DH', 'AH0') ('DH', 'AH0', 'T') ('DH', 'AH0') ('DH', 'AH0') ('DH', 'AH0') \n",
      "\n",
      "('W', 'AH1', 'Z') ('W', 'AH1', 'Z') ('W', 'AH0', 'Z') ('W', 'AH1', 'Z') ('W', 'AH0', 'Z') ('W', 'AH0', 'Z') ('W', 'IH1', 'CH') ('W', 'AH0', 'Z') ('W', 'AH0', 'Z') ('W', 'AO1', 'Z') ('W', 'AH0', 'Z') ('W', 'AH0', 'Z') ('W', 'IH0', 'TH') ('W', 'AO1', 'Z') ('W', 'AH0', 'Z') ('W', 'AH0', 'Z') ('W', 'AH0', 'Z') ('W', 'AH0', 'Z') ('W', 'IH1', 'TH') ('W', 'AH1', 'Z') \n",
      "\n",
      "('AH0',) ('AH1', 'V') ('AH0', 'V') ('AH0', 'V') ('AH0', 'V') ('AH1', 'V') ('AH0', 'V') ('AH0', 'V') ('AH1', 'V') ('AH0', 'V') ('AH1', 'P') ('AH1', 'V') \n",
      "\n",
      "('AY1',) ('AY1',) ('AY1',) ('AY1',) ('AY1',) ('ER0',) ('AY1',) ('AY1',) ('AY1',) ('HH', 'AW1') ('AY1',) \n",
      "\n",
      "('AH0',) ('AH0',) ('AH0',) ('AH0',) ('AH1', 'V') ('AH1', 'V') ('IH0', 'T') ('IH1', 'T') ('IH1', 'T') ('AE1', 'T') ('AH1', 'V') \n",
      "\n",
      "('M', 'AY1') ('M', 'AY1') ('M', 'AY1', 'T') ('M', 'AY1') ('M', 'AY1') ('M', 'AY1', 'T') ('M', 'AY1', 'T') ('M', 'AY1') ('M', 'AY1') \n",
      "\n",
      "('T', 'AH0') ('T', 'AH0') ('T', 'AH0') ('T', 'IH0') ('T', 'AH0') ('T', 'AH0') ('T', 'AH0') ('T', 'AH0') \n",
      "\n",
      "('HH', 'AE1', 'D') ('HH', 'AE1', 'D') ('HH', 'AE1', 'D') ('HH', 'AE1', 'D') ('HH', 'AE1', 'D') ('AE1', 'T') ('HH', 'AE1', 'D') ('HH', 'AE1', 'V') \n",
      "\n",
      "('W', 'AH1', 'T') ('W', 'IH0', 'TH') ('W', 'IH1', 'CH') ('W', 'IH1', 'CH') ('W', 'IH1', 'CH') ('W', 'IH1', 'CH') ('W', 'IH1', 'CH') \n",
      "\n",
      "('DH', 'AH1') ('AH0',) ('DH', 'AH0') ('AH0',) ('AH0',) ('AH0',) \n",
      "\n",
      "('W', 'ER0') ('W', 'ER1', 'S') ('W', 'AH0', 'Z') ('W', 'AH0', 'Z') ('W', 'AH1', 'T') \n",
      "\n",
      "('DH', 'EH1', 'R') ('DH', 'EH1', 'R') ('DH', 'EH1', 'R') ('DH', 'EH1', 'R') \n",
      "\n",
      "('B', 'IH0', 'N') ('IY1', 'V', 'IH0', 'N') ('B', 'IH0', 'N') \n",
      "\n",
      "('N', 'OW1') ('N', 'OW1') ('N', 'OW1') \n",
      "\n",
      "('IH0', 'N') ('AH0', 'N', 'D') ('AE1', 'N', 'D') \n",
      "\n",
      "('N', 'AA1', 'T') ('N', 'AA1', 'T') ('N', 'AA1', 'T') \n",
      "\n",
      "('W', 'UH1', 'D') ('W', 'AH0', 'Z') ('W', 'AH1', 'Z') \n",
      "\n",
      "('B', 'IY1') ('B', 'IY1') ('B', 'IY1') \n",
      "\n",
      "('AE1', 'N', 'D') ('AH0', 'N') ('AE1', 'N', 'D') \n",
      "\n",
      "('F', 'ER0') ('F', 'ER0') ('F', 'ER0') \n",
      "\n",
      "('AY1',) ('AY1',) ('AY1',) \n",
      "\n",
      "('IH1', 'T') ('IH0', 'T') ('IH0', 'T') \n",
      "\n",
      "('R', 'IY1', 'Z', 'AH0', 'N') ('S', 'IY1', 'Z', 'AH0', 'N') \n",
      "\n",
      "('HH', 'AE1', 'N', 'D') ('HH', 'AE1', 'N', 'D') \n",
      "\n",
      "('F', 'AE1', 'SH', 'AH0', 'N', 'D') ('F', 'AE1', 'SH', 'AH0', 'N', 'D') \n",
      "\n",
      "('S', 'EH1', 'V', 'R', 'AH0', 'L') ('S', 'AH1', 'M') \n",
      "\n",
      "('OW1', 'L', 'D') ('OW1', 'L', 'D') \n",
      "\n",
      "('AO1', 'R') ('AO1', 'R') \n",
      "\n",
      "('M', 'AY2', 'S', 'EH1', 'L', 'F') ('M', 'AY2', 'S', 'EH1', 'L', 'F') \n",
      "\n",
      "('F', 'R', 'ER0') ('F', 'ER0') \n",
      "\n",
      "('D', 'IH0', 'D') ('D', 'IH1', 'D') \n",
      "\n",
      "('N', 'AH1', 'TH', 'IH0', 'NG') ('N', 'AH1', 'TH', 'IH0', 'NG') \n",
      "\n",
      "('HH', 'AE1', 'F') ('HH', 'AE1', 'F') \n",
      "\n",
      "('K', 'R', 'AW1', 'D') ('P', 'L', 'AW1', 'D') \n",
      "\n",
      "('AH2', 'N', 'K', 'AA1', 'M', 'AH0', 'N', 'L', 'IY0') ('AH2', 'N', 'K', 'AA1', 'M', 'AH0', 'N', 'L', 'IY0') \n",
      "\n",
      "('SH', 'IY1') ('SH', 'IY1') \n",
      "\n",
      "('HH', 'AA1', 'R', 'D', 'L', 'IY0') ('HH', 'AA1', 'R', 'D', 'L', 'IY0') \n",
      "\n",
      "('M', 'AE1', 'JH') ('M', 'AE1', 'JH') \n",
      "\n",
      "('AE1', 'N') ('AE1', 'N', 'D') \n",
      "\n",
      "('M', 'IY1') ('M', 'IY1') \n",
      "\n",
      "('HH', 'IY1') \n",
      "\n",
      "('IH0', 'M', 'P', 'ER1', 'V', 'IY0', 'AH0', 'S') \n",
      "\n",
      "('AO1', 'L') \n",
      "\n",
      "('N', 'AY1', 'T') \n",
      "\n",
      "('IH0', 'T') \n",
      "\n",
      "('B', 'L', 'OW1', 'IH0', 'NG') \n",
      "\n",
      "('R', 'EY1', 'N', 'IH0', 'NG') \n",
      "\n",
      "('HH', 'OW1', 'L') \n",
      "\n",
      "('TH', 'IH1', 'NG') \n",
      "\n",
      "('T', 'R', 'AY1', 'F', 'AH0', 'L') \n",
      "\n",
      "('AA1', 'D') \n",
      "\n",
      "('B', 'AO1', 'T') \n",
      "\n",
      "('S', 'AH1', 'M', 'TH', 'IH0', 'NG') \n",
      "\n",
      "('AY1',) \n",
      "\n",
      "('M', 'IY1', 'N') \n",
      "\n",
      "('M', 'IH1', 'S', 'IH0', 'Z') \n",
      "\n",
      "('W', 'IH1', 'L', 'S', 'AH0', 'N') \n",
      "\n",
      "('IH0', 'L', 'UW1', 'ZH', 'AH0', 'N', 'Z') \n",
      "\n",
      "('P', 'R', 'EH1', 'Z', 'AH0', 'N', 'T', 'L', 'IY0') \n",
      "\n",
      "('F', 'IY1', 'T') \n",
      "\n",
      "('W', 'ER0') \n",
      "\n",
      "('HH', 'ER1', 'D') \n",
      "\n",
      "('AH0', 'D', 'V', 'AE1', 'N', 'S', 'IH0', 'NG') \n",
      "\n",
      "('AH0', 'L', 'AO1', 'NG') \n",
      "\n",
      "('P', 'AE1', 'S', 'IH0', 'JH') \n",
      "\n",
      "('S', 'EH1', 'V', 'R', 'AH0', 'L') \n",
      "\n",
      "('P', 'EH1', 'R', 'Z') \n",
      "\n",
      "('IH1', 'T') \n",
      "\n",
      "('S', 'IY1', 'M', 'D') \n",
      "\n",
      "('AE1', 'N', 'D') \n",
      "\n",
      "('AH0',) \n",
      "\n",
      "('L', 'AY1', 'T') \n",
      "\n",
      "('G', 'L', 'IY1', 'M', 'D') \n",
      "\n",
      "('TH', 'R', 'UW1') \n",
      "\n",
      "('W', 'IH1', 'N', 'D', 'OW0') \n",
      "\n",
      "('OW1', 'V', 'ER0') \n",
      "\n",
      "('D', 'AO1', 'R') \n",
      "\n",
      "('AE1', 'F', 'T', 'ER0') \n",
      "\n",
      "('V', 'AE1', 'S', 'T') \n",
      "\n",
      "('AH0', 'M', 'AW1', 'N', 'T') \n",
      "\n",
      "('AH0', 'N', 'F', 'AE1', 'S', 'N', 'IH0', 'NG') \n",
      "\n",
      "('D', 'AO1', 'R') \n",
      "\n",
      "('OW1', 'P', 'AH0', 'N', 'D') \n",
      "\n",
      "('AH0', 'N', 'D') \n",
      "\n",
      "('AA1', 'N') \n",
      "\n",
      "('TH', 'R', 'EH1', 'SH', 'OW2', 'L', 'D') \n",
      "\n",
      "('S', 'T', 'UH1', 'D') \n",
      "\n",
      "('AH0',) \n",
      "\n",
      "('G', 'ER1', 'L') \n",
      "\n",
      "('W', 'IH0', 'TH') \n",
      "\n",
      "('L', 'AY1', 'T', 'IH0', 'D') \n",
      "\n",
      "('K', 'AE1', 'N', 'D', 'AH0', 'L') \n",
      "\n",
      "('IH0', 'N') \n",
      "\n",
      "('HH', 'ER0') \n",
      "\n",
      "('AY1',) \n",
      "\n",
      "('T', 'OW1', 'L', 'D') \n",
      "\n",
      "('B', 'EH1', 'L') \n",
      "\n",
      "('AH0', 'G', 'EH1', 'N') \n",
      "\n",
      "('L', 'AO1', 'NG') \n",
      "\n",
      "('B', 'AH0', 'N') \n",
      "\n",
      "('W', 'IH1', 'SH', 'IH0', 'NG') \n",
      "\n",
      "('DH', 'AH0', 'T') \n",
      "\n",
      "('AH0', 'N') \n",
      "\n",
      "('K', 'R', 'IH1', 'S', 'M', 'AH0', 'S') \n",
      "\n",
      "('K', 'AH0', 'M', 'P', 'L', 'IY1', 'T', 'L', 'IY0') \n",
      "\n",
      "('IH0', 'K', 'S', 'T', 'IH1', 'NG', 'K', 'T') \n",
      "\n",
      "('B', 'IH0', 'F', 'AO1', 'R') \n",
      "\n",
      "('AY1',) \n",
      "\n",
      "('TH', 'AO1', 'T') \n",
      "\n",
      "('AE0', 'D', 'V', 'EH1', 'N', 'CH', 'ER0', 'IH0', 'NG') \n",
      "\n",
      "('K', 'W', 'EH1', 'S', 'T') \n",
      "\n",
      "('W', 'AH1', 'N') \n",
      "\n",
      "('D', 'IH1', 'D') \n",
      "\n",
      "('N', 'AA1', 'T') \n",
      "\n",
      "('IH0', 'K', 'S', 'P', 'EH1', 'K', 'T') \n",
      "\n",
      "('P', 'R', 'IH1', 'N', 'S', 'L', 'IY0') \n",
      "\n",
      "('EH2', 'N', 'ER0', 'T', 'EY1', 'N', 'M', 'AH0', 'N', 'T') \n",
      "\n",
      "('AE1', 'N', 'S', 'ER0') \n",
      "\n",
      "('DH', 'OW1') \n",
      "\n",
      "('AH0', 'L', 'AW1', 'D') \n",
      "\n",
      "('AH0',) \n",
      "\n",
      "('M', 'AO1', 'R') \n",
      "\n",
      "('DH', 'AH0', 'N') \n",
      "\n",
      "('D', 'IY1', 'S', 'AH0', 'N', 'T') \n",
      "\n",
      "('IH1', 'N', 'T', 'ER0', 'V', 'AH0', 'L') \n",
      "\n",
      "('IH0', 'M', 'AE1', 'JH', 'AH0', 'N') \n",
      "\n",
      "('DH', 'EH1', 'R') \n",
      "\n",
      "('K', 'AY1', 'N', 'D', 'Z') \n",
      "\n",
      "('AH0', 'V') \n",
      "\n",
      "('K', 'R', 'IH1', 'S', 'M', 'AH0', 'S', 'IH0', 'Z') \n",
      "\n",
      "('B', 'AH1', 'T') \n",
      "\n",
      "('IH0', 'T') \n",
      "\n",
      "('K', 'UH1', 'D') \n",
      "\n",
      "('B', 'IY1') \n",
      "\n",
      "('DH', 'AH0', 'N') \n",
      "\n",
      "('CH', 'AA1', 'P') \n",
      "\n",
      "('IH0', 'N') \n",
      "\n",
      "('CH', 'EY1', 'M', 'B', 'ER0', 'Z') \n",
      "\n",
      "('HH', 'AO1', 'R', 'ER0') \n",
      "\n",
      "('HH', 'AO1', 'R', 'ER0', 'Z') \n",
      "\n",
      "('K', 'L', 'AH1', 'B') \n",
      "\n",
      "('K', 'AH1', 'Z', 'AH0', 'N') \n",
      "\n",
      "('L', 'UW1', 'S', 'IY0', 'Z') \n",
      "\n",
      "('N', 'OW1', 'SH', 'AH0', 'N') \n",
      "\n",
      "('K', 'AO1', 'L', 'Z') \n",
      "\n",
      "('F', 'EH1', 'S', 'T', 'IH0', 'V') \n",
      "\n",
      "('F', 'EH1', 'L', 'T') \n",
      "\n",
      "('K', 'W', 'AY1', 'T') \n",
      "\n",
      "('L', 'AY1', 'V', 'L', 'IY0') \n",
      "\n",
      "('EH1', 'Z') \n",
      "\n",
      "('AY1',) \n",
      "\n",
      "('M', 'IH1', 'NG', 'G', 'AH0', 'L', 'D') \n",
      "\n",
      "('K', 'R', 'IH1', 'S', 'M', 'AH0', 'S') \n",
      "\n",
      "('L', 'UH1', 'K', 'IH0', 'NG') \n",
      "\n",
      "('TH', 'IH1', 'NG', 'Z') \n",
      "\n",
      "('T', 'ER1', 'N') \n",
      "\n",
      "('AW1', 'T') \n",
      "\n",
      "('B', 'IY1') \n",
      "\n",
      "('AE2', 'B', 'S', 'AH0', 'L', 'UW1', 'T', 'L', 'IY0') \n",
      "\n",
      "('P', 'R', 'IH0', 'P', 'AA1', 'S', 'T', 'ER0', 'AH0', 'S') \n",
      "\n",
      "('AE1', 'S', 'K') \n",
      "\n",
      "('B', 'IY2', 'AO1', 'N', 'D') \n",
      "\n",
      "('IH0', 'T') \n",
      "\n",
      "('S', 'EH1', 'D') \n",
      "\n",
      "('AH0', 'B', 'AW1', 'T') \n",
      "\n",
      "('S', 'AO1', 'R', 'T') \n",
      "\n",
      "('AH0', 'K', 'AA2', 'M', 'AH0', 'D', 'EY1', 'SH', 'AH0', 'N') \n",
      "\n",
      "('B', 'IY0') \n",
      "\n",
      "('P', 'R', 'AH0', 'V', 'AY1', 'D', 'IH0', 'D') \n",
      "\n",
      "('AH0', 'B', 'AW1', 'T') \n",
      "\n",
      "('K', 'AY1', 'N', 'D') \n",
      "\n",
      "('IH0', 'S', 'T', 'AE1', 'B', 'L', 'IH0', 'SH', 'M', 'AH0', 'N', 'T') \n",
      "\n",
      "('M', 'EY0', 'N', 'T', 'EY1', 'N', 'D') \n",
      "\n",
      "('T', 'EY1', 'B', 'AH0', 'L') \n",
      "\n",
      "('K', 'EH1', 'P', 'T') \n",
      "\n",
      "('W', 'AH1', 'N') \n",
      "\n",
      "('K', 'AH1', 'M') \n",
      "\n",
      "('T', 'AH0') \n",
      "\n",
      "('M', 'IY1', 'T') \n",
      "\n",
      "('M', 'IY1') \n",
      "\n",
      "('V', 'IH1', 'L', 'AH0', 'JH') \n",
      "\n",
      "('AH0', 'B', 'AW1', 'T') \n",
      "\n",
      "('AH0',) \n",
      "\n",
      "('M', 'AY1', 'L') \n",
      "\n",
      "('AE1', 'N', 'D') \n",
      "\n",
      "('HH', 'AE1', 'NG', 'ER0') \n",
      "\n",
      "('D', 'IY1', 'N') \n",
      "\n",
      "('DH', 'AH0') \n",
      "\n",
      "('HH', 'AW1', 'S') \n",
      "\n",
      "('S', 'T', 'EH1', 'P', 'S') \n",
      "\n",
      "('W', 'ER0') \n",
      "\n",
      "('B', 'EH1', 'N', 'T') \n",
      "\n",
      "('AH0', 'B', 'AW1', 'T') \n",
      "\n",
      "('F', 'AO1', 'R') \n",
      "\n",
      "('M', 'AY1', 'L', 'Z') \n",
      "\n",
      "('B', 'AY1') \n",
      "\n",
      "('R', 'OW1', 'D') \n",
      "\n",
      "('F', 'AA1', 'R') \n",
      "\n",
      "('IH0', 'T') \n",
      "\n",
      "('AH0', 'K', 'R', 'AO1', 'S') \n",
      "\n",
      "('F', 'IY1', 'L', 'D', 'Z') \n",
      "\n",
      "('IH0', 'N', 'F', 'AO1', 'R', 'M', 'AH0', 'N', 'T') \n",
      "\n",
      "('D', 'IH1', 'D') \n",
      "\n",
      "('M', 'EH1', 'N', 'SH', 'AH0', 'N') \n",
      "\n",
      "('R', 'IH0', 'P', 'L', 'AY1') \n",
      "\n",
      "('R', 'IH1', 'T', 'AH0', 'N') \n",
      "\n",
      "('IH0', 'N') \n",
      "\n",
      "('S', 'P', 'R', 'AO1', 'L', 'IH0', 'NG') \n",
      "\n",
      "('F', 'EH1', 'M', 'AH0', 'N', 'AH0', 'N') \n",
      "\n",
      "('IH1', 'T') \n",
      "\n",
      "('L', 'IH1', 'T', 'AH0', 'L') \n",
      "\n",
      "('V', 'EY1', 'G') \n",
      "\n",
      "('IH2', 'N', 'F', 'ER0', 'M', 'EY1', 'SH', 'AH0', 'N') \n",
      "\n",
      "('G', 'R', 'IY1', 'T', 'IH0', 'D') \n",
      "\n",
      "('W', 'AH1', 'T') \n",
      "\n",
      "('S', 'AW1', 'N', 'D', 'AH0', 'D') \n",
      "\n",
      "('L', 'AY1', 'K') \n",
      "\n",
      "('AH0',) \n",
      "\n",
      "('K', 'AO1', 'R', 'AH0', 'S') \n",
      "\n",
      "('L', 'AE1', 'F', 'T', 'ER0') \n",
      "\n",
      "('AH0',) \n",
      "\n",
      "('HH', 'AO1', 'R', 'AH0', 'B', 'AH0', 'L') \n",
      "\n",
      "('JH', 'ER1', 'N', 'IY0') \n",
      "\n",
      "('DH', 'EH1', 'R', 'Z') \n",
      "\n",
      "('N', 'AA1', 'K', 'ER0') \n",
      "\n",
      "('IH1', 'F') \n",
      "\n",
      "('N', 'AH1', 'N') \n",
      "\n",
      "('EH1', 'M') \n",
      "\n",
      "('HH', 'AE1', 'V', 'AH0', 'N') \n",
      "\n",
      "('T', 'W', 'IH1', 'S', 'T', 'IH0', 'D') \n",
      "\n",
      "('IH0', 'T') \n",
      "\n",
      "('AO1', 'F') \n",
      "\n",
      "('HH', 'IY1', 'R') \n",
      "\n",
      "('W', 'IY1') \n",
      "\n",
      "('DH', 'AE1', 'T') \n",
      "\n",
      "('B', 'IY1') \n",
      "\n",
      "('S', 'OW1') \n",
      "\n",
      "('HH', 'W', 'EH1', 'N') \n",
      "\n",
      "('T', 'R', 'AE1', 'P') \n",
      "\n",
      "('D', 'IH1', 'D') \n",
      "\n",
      "('AH0', 'P', 'IH1', 'R') \n",
      "\n",
      "('L', 'UH1', 'K', 'T') \n",
      "\n",
      "('L', 'AY1', 'K') \n",
      "\n",
      "('OW1', 'P', 'AH0', 'N') \n",
      "\n",
      "('S', 'P', 'R', 'IH1', 'NG') \n",
      "\n",
      "('K', 'AA1', 'R', 'T') \n",
      "\n",
      "('HH', 'UW1') \n",
      "\n",
      "('L', 'IH1', 'V', 'Z') \n",
      "\n",
      "('HH', 'IY1', 'R') \n",
      "\n",
      "('AA1', 'R') \n",
      "\n",
      "('P', 'IY1', 'P', 'AH0', 'L') \n",
      "\n",
      "('M', 'AE1', 'D') \n",
      "\n",
      "('R', 'AH1', 'SH') \n",
      "\n",
      "('R', 'IY0', 'T', 'R', 'IY1', 'T', 'IH0', 'NG') \n",
      "\n",
      "('F', 'IY1', 'T') \n",
      "\n",
      "('IH0', 'K', 'S', 'P', 'AA1', 'S', 'CH', 'AH0', 'L', 'EY2', 'T', 'IH0', 'NG') \n",
      "\n",
      "('V', 'OY1', 'S') \n",
      "\n",
      "('DH', 'EH1', 'N') \n",
      "\n",
      "('D', 'AA1', 'R', 'K', 'N', 'AH0', 'S') \n",
      "\n",
      "('AH0', 'G', 'EH1', 'N') \n",
      "\n",
      "('S', 'AY1', 'L', 'AH0', 'N', 'S') \n",
      "\n",
      "('M', 'EY1', 'B', 'IY0') \n",
      "\n",
      "('T', 'AH0') \n",
      "\n",
      "('G', 'EY1', 'M', 'Z') \n",
      "\n",
      "('W', 'AA1', 'N', 'T', 'S') \n",
      "\n",
      "('R', 'AW1', 'Z', 'IH0', 'NG') \n",
      "\n",
      "('AH1', 'N', 'D', 'ER0') \n",
      "\n",
      "('S', 'AH1', 'CH') \n",
      "\n",
      "('S', 'ER1', 'K', 'AH0', 'M', 'S', 'T', 'AE2', 'N', 'S', 'AH0', 'Z') \n",
      "\n",
      "('L', 'AY1', 'K', 'L', 'IY0') \n",
      "\n",
      "('T', 'AH0') \n",
      "\n",
      "('L', 'AY1', 'V', 'L', 'IY0') \n",
      "\n",
      "('HH', 'ER0', 'S', 'EH1', 'L', 'F') \n",
      "\n",
      "('B', 'AH1', 'T') \n",
      "\n",
      "('HH', 'ER0') \n",
      "\n",
      "('N', 'EY1', 'M') \n",
      "\n",
      "('AE1', 'K', 'S', 'AH0', 'D', 'AH0', 'N', 'T') \n",
      "\n",
      "('HH', 'ER0') \n",
      "\n",
      "('K', 'R', 'IH1', 'S', 'CH', 'IH0', 'N') \n",
      "\n",
      "('N', 'EY1', 'M') \n",
      "\n",
      "('D', 'IH2', 'S', 'AY1', 'D', 'IH0', 'D') \n",
      "\n",
      "('M', 'IY1') \n",
      "\n",
      "('G', 'OW1') \n",
      "\n",
      "('IH1', 'T') \n",
      "\n",
      "('IH1', 'Z') \n",
      "\n",
      "('S', 'AH1', 'M') \n",
      "\n",
      "('S', 'AE2', 'T', 'IH0', 'S', 'F', 'AE1', 'K', 'SH', 'AH0', 'N') \n",
      "\n",
      "('EY1', 'B', 'AH0', 'L') \n",
      "\n",
      "('R', 'IH0', 'F', 'L', 'EH1', 'K', 'T') \n",
      "\n",
      "('DH', 'AE1', 'T') \n",
      "\n",
      "('AY1',) \n",
      "\n",
      "('M', 'EY1', 'D') \n",
      "\n",
      "('W', 'AO1', 'R', 'M') \n",
      "\n",
      "('DH', 'IY0') \n",
      "\n",
      "('AH0', 'F', 'IH1', 'SH', 'AH0', 'L', 'Z') \n",
      "\n",
      "('HH', 'AW2', 'EH1', 'V', 'ER0') \n",
      "\n",
      "('K', 'OW1', 'L', 'D') \n",
      "\n",
      "('B', 'IH1', 'N') \n",
      "\n",
      "('CH', 'IH1', 'L', 'D') \n",
      "\n",
      "('B', 'OW1', 'N') \n",
      "\n",
      "('W', 'EH1', 'T') \n",
      "\n",
      "('T', 'AY1', 'ER0', 'D') \n",
      "\n",
      "('HH', 'AH1', 'NG', 'G', 'R', 'IY0') \n",
      "\n",
      "('IH1', 'N') \n",
      "\n",
      "('D', 'AH0', 'P', 'AA1', 'Z', 'IH0', 'T', 'IH0', 'D') \n",
      "\n",
      "('L', 'AH1', 'G', 'IH0', 'JH') \n",
      "\n",
      "('W', 'EH1', 'N') \n",
      "\n",
      "('L', 'AE1', 'S', 'T') \n",
      "\n",
      "('AY1',) \n",
      "\n",
      "('R', 'IY1', 'CH', 'T') \n",
      "\n",
      "('K', 'R', 'AA1', 'F', 'T', 'AH0', 'N') \n",
      "\n",
      "('JH', 'ER1', 'N', 'IY0', 'Z') \n",
      "\n",
      "('EH1', 'N', 'D') \n",
      "\n",
      "('T', 'ER1', 'N', 'D') \n",
      "\n",
      "('AW1', 'T') \n",
      "\n",
      "('S', 'T', 'EY1', 'SH', 'AH0', 'N') \n",
      "\n",
      "('S', 'T', 'AE1', 'F') \n",
      "\n",
      "('K', 'AH0', 'N', 'S', 'IH1', 'S', 'T', 'AH0', 'D') \n",
      "\n",
      "('AH0',) \n",
      "\n",
      "('W', 'IH1', 'T', 'IH0', 'D') \n",
      "\n",
      "('IH2', 'N', 'D', 'AH0', 'V', 'IH1', 'JH', 'AH0', 'W', 'AH0', 'L') \n",
      "\n",
      "('HH', 'UW1') \n",
      "\n",
      "('S', 'T', 'EY1', 'SH', 'AH0', 'N', 'M', 'AE2', 'S', 'T', 'ER0') \n",
      "\n",
      "('P', 'AO1', 'R', 'T', 'ER0') \n",
      "\n",
      "('K', 'L', 'ER1', 'K') \n",
      "\n",
      "('K', 'AH0', 'M', 'B', 'AY1', 'N', 'D') \n",
      "\n",
      "('AH0', 'N', 'D') \n",
      "\n",
      "('AH0',) \n",
      "\n",
      "('HH', 'AH1', 'L', 'K', 'IH0', 'NG') \n",
      "\n",
      "('L', 'AE1', 'D') \n",
      "\n",
      "('HH', 'UW1') \n",
      "\n",
      "('W', 'AH2', 'T', 'EH1', 'V', 'ER0') \n",
      "\n",
      "('EH1', 'L', 'S') \n",
      "\n",
      "('D', 'UW1') \n",
      "\n",
      "('AY1', 'M') \n",
      "\n",
      "('M', 'IH1', 'S', 'T', 'ER0') \n",
      "\n",
      "('K', 'R', 'IH1', 'S', 'T', 'AH0', 'F', 'ER0') \n",
      "\n",
      "('F', 'R', 'AH1', 'M') \n",
      "\n",
      "('L', 'AH1', 'N', 'D', 'AH0', 'N') \n",
      "\n",
      "('B', 'EH1', 'T', 'ER0') \n",
      "\n",
      "('R', 'IH1', 'NG') \n",
      "\n",
      "('AH0', 'G', 'EH1', 'N') \n",
      "\n",
      "('S', 'AH0', 'G', 'JH', 'EH1', 'S', 'T', 'AH0', 'D') \n",
      "\n",
      "('D', 'R', 'AY1', 'V', 'ER0') \n",
      "\n",
      "('HH', 'AA1', 'R', 'D') \n",
      "\n",
      "('B', 'EH1', 'L') \n",
      "\n",
      "('R', 'IH0', 'V', 'ER1', 'B', 'ER0', 'EY2', 'T', 'IH0', 'D') \n",
      "\n",
      "('TH', 'R', 'UW1') \n",
      "\n",
      "2.548%\n"
     ]
    }
   ],
   "source": [
    "dists = []\n",
    "for row in partition:\n",
    "    clust = []\n",
    "    for el in row:\n",
    "        phones = \"-\".join(labels[el])\n",
    "        print(phones, end=\" \")\n",
    "        clust.append(labels[el])\n",
    "\n",
    "    dist = normalized_edit_distance(clust)\n",
    "    dists.append(dist)\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "print(f\"{np.mean(dists) * 100:.3f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
