{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from utils.features import DataSet\n",
    "\n",
    "name = \"librispeech-dev-clean\"\n",
    "in_dir = Path(\"data/dev-clean\")\n",
    "align_dir = Path(\"data/alignments/dev-clean\")\n",
    "feat_dir = Path(\"features\")\n",
    "audio_ext = \".flac\" \n",
    "\n",
    "dataset = DataSet(\n",
    "    name, in_dir, align_dir, feat_dir, audio_ext \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63137\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "audio_paths = list(dataset.in_dir.rglob(f\"**/*{dataset.audio_ext}\"))\n",
    "sample_feature_paths = list(Path(dataset.feat_dir / \"dusted_units/0.2/\").rglob(\"**/*.npy\"))\n",
    "\n",
    "sample = False\n",
    "sample_size = None\n",
    "\n",
    "if sample: \n",
    "    # sample_audio_paths = random.sample(audio_paths, sample_size)\n",
    "    sample_feature_paths = random.sample(sample_feature_paths, sample_size)\n",
    "    # sample_feature_paths = feature_paths[0:sample_size]\n",
    "\n",
    "sample_size = len(sample_feature_paths)\n",
    "file_map = {}\n",
    "for i, feature in enumerate(sample_feature_paths):\n",
    "    file_map[i] = feature\n",
    "\n",
    "print(sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_generator(num_paths):\n",
    "    for i in range(num_paths):\n",
    "        for j in range(i + 1, num_paths):\n",
    "            yield i, j\n",
    "\n",
    "\n",
    "def get_batch_of_paths(num_paths, chunk_limit=100):\n",
    "    \"\"\"Generate sequential batches of (i, j) path pairs.\"\"\"\n",
    "    pairs = pair_generator(num_paths) \n",
    "    chunk = [] \n",
    "\n",
    "    for idx, (i, j) in enumerate(pairs, 1):\n",
    "        chunk.append((i, j))\n",
    "\n",
    "        if idx % chunk_limit == 0:\n",
    "            yield chunk \n",
    "            chunk = [] \n",
    "\n",
    "    if chunk:  \n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.features import WordUnit\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def load_word(word_path, word_id, align_df):\n",
    "\n",
    "    \"\"\"Loads a word unit with metadata and encoding information.\"\"\"\n",
    "    # Load encoding units\n",
    "    units = np.load(word_path)\n",
    "    \n",
    "    # Extract filename and word index\n",
    "    parts = word_path.stem.split(\"_\")\n",
    "    filename, index = parts[0], int(parts[1])\n",
    "\n",
    "    # Filter align_df once using .query()\n",
    "    word_df = align_df.query(\"filename == @filename and word_id == @index\")\n",
    "    \n",
    "    if word_df.empty:\n",
    "        return None  # Early exit if word not found\n",
    "\n",
    "    # Extract the actual word text efficiently\n",
    "    true_word = word_df[\"text\"].iat[0] if isinstance(word_df[\"text\"].iat[0], str) else \"_\"\n",
    "\n",
    "    # Create WordUnit object\n",
    "    word = WordUnit(\n",
    "        id=word_id,\n",
    "        filename=filename,\n",
    "        index=index,\n",
    "        true_word=true_word,\n",
    "        boundaries=[word_df[\"word_start\"].iat[0], word_df[\"word_end\"].iat[0]],\n",
    "    )\n",
    "\n",
    "    # Update encoding with loaded units\n",
    "    word.update_encoding(units)\n",
    "    return word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_key(key, file_map, words_cache, keys, align_df):\n",
    "    \"\"\"Helper function to process a single key.\"\"\"\n",
    "    if key in words_cache:\n",
    "        return words_cache[key]  # Retrieve from cache\n",
    "    \n",
    "    path = file_map.get(key)\n",
    "    if path is None:\n",
    "        print(f\"Warning: No file found for key '{key}' in file_map\")\n",
    "        return None  # Skip processing for missing files\n",
    "\n",
    "    word = load_word(path, key, align_df)  # Load word\n",
    "    words_cache[key] = word  # Cache it\n",
    "    keys.add(key)\n",
    "    return word\n",
    "\n",
    "def load_units_for_chunk(dataset, chunk, align_df=None, file_map=None):\n",
    "    \"\"\"Optimized function for loading units for a chunk with parallel loading using joblib.\"\"\"\n",
    "\n",
    "    # Use Parquet if available for faster reading\n",
    "    if align_df is None:\n",
    "        csv_path = dataset.align_dir / \"alignments.csv\"\n",
    "        align_df = pd.read_csv(csv_path)\n",
    "    \n",
    "    words_cache = {}  # Cache for fast word retrieval\n",
    "    keys = set()\n",
    "    chunk_words = []\n",
    "\n",
    "    # Process words in parallel using joblib\n",
    "    for pair in chunk:\n",
    "        pair_keys = tuple(pair.keys())\n",
    "\n",
    "        words= []\n",
    "        for key in pair_keys:\n",
    "            words.append(process_key(key, file_map, words_cache, keys, align_df))\n",
    "            \n",
    "        chunk_words.append(tuple(words))\n",
    "\n",
    "    return chunk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import editdistance\n",
    "\n",
    "def calculate_distance_per_chunk(chunk_words):\n",
    "    \"\"\"Process sub-chunk and return computed distances with indices\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for pair in chunk_words:\n",
    "        encoding_i = torch.from_numpy(pair[0].clean_encoding)\n",
    "        encoding_j = torch.from_numpy(pair[1].clean_encoding)\n",
    "\n",
    "        shapes = torch.tensor([encoding_i.size()[0], encoding_j.size()[0]])\n",
    "        length = torch.max(shapes)\n",
    "\n",
    "        dist = 0\n",
    "        if length > 0:\n",
    "            dist =  editdistance.eval(encoding_i, encoding_j) / length\n",
    "\n",
    "        results.append((pair[0].id, pair[1].id, dist))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   0%|          | 0/1993109 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable function object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/danel/Documents/acoustic-units/.env/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"/home/danel/Documents/acoustic-units/.env/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/danel/Documents/acoustic-units/.env/lib/python3.12/site-packages/joblib/parallel.py\", line 599, in __call__\n    for func, args, kwargs in self.items]\n        ^^^^^^^^^^^^^^^^^^\nTypeError: cannot unpack non-iterable function object\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m\n\u001b[1;32m     14\u001b[0m chunk_paths \u001b[38;5;241m=\u001b[39m [{i: sample_feature_paths[i], j: sample_feature_paths[j]} \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m chunk]\n\u001b[1;32m     16\u001b[0m chunk_words \u001b[38;5;241m=\u001b[39m load_units_for_chunk(\n\u001b[1;32m     17\u001b[0m     dataset, chunk_paths, align_df\u001b[38;5;241m=\u001b[39malign_df, file_map\u001b[38;5;241m=\u001b[39mfile_map\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 19\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalculate_distance_per_chunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_words\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,j, distance \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m     22\u001b[0m     dist_mat[i, j] \u001b[38;5;241m=\u001b[39m distance \n",
      "File \u001b[0;32m~/Documents/acoustic-units/.env/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/acoustic-units/.env/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/acoustic-units/.env/lib/python3.12/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/acoustic-units/.env/lib/python3.12/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/acoustic-units/.env/lib/python3.12/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/acoustic-units/.env/lib/python3.12/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable function object"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "num_features = len(sample_feature_paths)\n",
    "dist_mat = torch.zeros((sample_size, sample_size), dtype=torch.float32)\n",
    "align_df = pd.read_csv(dataset.align_dir / \"alignments.csv\")\n",
    "\n",
    "chunk_limit = 1000\n",
    "num_pairs = num_features * (num_features - 1) // 2\n",
    "num_chunks = (num_pairs + chunk_limit - 1) // chunk_limit \n",
    "\n",
    "start_time = time.perf_counter()\n",
    "for chunk in tqdm(get_batch_of_paths(num_features, chunk_limit=100), total=num_chunks, desc=\"Processing chunks\"):\n",
    "    chunk_paths = [{i: sample_feature_paths[i], j: sample_feature_paths[j]} for i, j in chunk]\n",
    "\n",
    "    chunk_words = load_units_for_chunk(\n",
    "        dataset, chunk_paths, align_df=align_df, file_map=file_map\n",
    "    )\n",
    "    futures = Parallel(n_jobs=2)(delayed(calculate_distance_per_chunk)(chunk_words))\n",
    "    \n",
    "    for future in futures:\n",
    "        i,j, distance = future.result()\n",
    "        dist_mat[i, j] = distance \n",
    "\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f\"Total time: {end_time - start_time}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
