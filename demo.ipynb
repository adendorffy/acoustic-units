{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from encode import sample_files, get_units\n",
    "import pandas as pd\n",
    "\n",
    "audio_dir = Path(\"data/dev-clean\")\n",
    "audio_ext = \".flac\"\n",
    "align_path = Path(\"data/alignments/dev-clean/alignments.csv\")\n",
    "save_dir = Path(\"features/\")\n",
    "\n",
    "align_df = pd.read_csv(align_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths, sample_size = sample_files(\n",
    "    audio_dir=audio_dir, audio_ext=audio_ext, sample_size=-1\n",
    ")\n",
    "\n",
    "gamma = 0.1\n",
    "\n",
    "get_units(paths=paths, align_df=align_df, gamma=gamma, layer=7, save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distance import process_chunks\n",
    "\n",
    "gamma = 0.2\n",
    "feat_dir = Path(f\"features/{gamma}\")\n",
    "csv_path = Path(f\"output/{gamma}/info.csv\")\n",
    "dist_mat_out_path = Path(f\"output/{gamma}/dist_mat.npz\")\n",
    "chunk_limit = 1000000\n",
    "\n",
    "process_chunks(\n",
    "    feat_dir=feat_dir,\n",
    "    info_csv_path=csv_path,\n",
    "    dist_mat_out_path=dist_mat_out_path,\n",
    "    chunk_limit=chunk_limit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "csv_path = \"output/0.2/info.csv\"\n",
    "dist_mat_out_path = Path(\"output/0.2/dist_mat.npz\")\n",
    "\n",
    "info_df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m dist_mat = np.load(dist_mat_out_path)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m dist_mat = \u001b[43mdist_mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdist_mat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Edit-Clusters/.env/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:258\u001b[39m, in \u001b[36mNpzFile.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m magic == \u001b[38;5;28mformat\u001b[39m.MAGIC_PREFIX:\n\u001b[32m    257\u001b[39m     \u001b[38;5;28mbytes\u001b[39m = \u001b[38;5;28mself\u001b[39m.zip.open(key)\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    263\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.zip.read(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Edit-Clusters/.env/lib/python3.12/site-packages/numpy/lib/format.py:858\u001b[39m, in \u001b[36mread_array\u001b[39m\u001b[34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[39m\n\u001b[32m    856\u001b[39m             read_count = \u001b[38;5;28mmin\u001b[39m(max_read_count, count - i)\n\u001b[32m    857\u001b[39m             read_size = \u001b[38;5;28mint\u001b[39m(read_count * dtype.itemsize)\n\u001b[32m--> \u001b[39m\u001b[32m858\u001b[39m             data = \u001b[43m_read_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43marray data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    859\u001b[39m             array[i:i+read_count] = numpy.frombuffer(data, dtype=dtype,\n\u001b[32m    860\u001b[39m                                                      count=read_count)\n\u001b[32m    862\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fortran_order:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Edit-Clusters/.env/lib/python3.12/site-packages/numpy/lib/format.py:993\u001b[39m, in \u001b[36m_read_bytes\u001b[39m\u001b[34m(fp, size, error_template)\u001b[39m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;66;03m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[32m    990\u001b[39m     \u001b[38;5;66;03m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[32m    991\u001b[39m     \u001b[38;5;66;03m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[32m    992\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m993\u001b[39m         r = \u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    994\u001b[39m         data += r\n\u001b[32m    995\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(r) == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) == size:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/zipfile/__init__.py:989\u001b[39m, in \u001b[36mZipExtFile.read\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m    987\u001b[39m \u001b[38;5;28mself\u001b[39m._offset = \u001b[32m0\u001b[39m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m n > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._eof:\n\u001b[32m--> \u001b[39m\u001b[32m989\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    990\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n < \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[32m    991\u001b[39m         \u001b[38;5;28mself\u001b[39m._readbuffer = data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/zipfile/__init__.py:1065\u001b[39m, in \u001b[36mZipExtFile._read1\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compress_type == ZIP_DEFLATED:\n\u001b[32m   1064\u001b[39m     n = \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m.MIN_READ_SIZE)\n\u001b[32m-> \u001b[39m\u001b[32m1065\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decompressor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1066\u001b[39m     \u001b[38;5;28mself\u001b[39m._eof = (\u001b[38;5;28mself\u001b[39m._decompressor.eof \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1067\u001b[39m                  \u001b[38;5;28mself\u001b[39m._compress_left <= \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m   1068\u001b[39m                  \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decompressor.unconsumed_tail)\n\u001b[32m   1069\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._eof:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "dist_mat = np.load(dist_mat_out_path)\n",
    "dist_mat = dist_mat[dist_mat.files[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting to Sparse: 100%|██████████| 127/127 [00:01<00:00, 70.75chunk/s]\n"
     ]
    }
   ],
   "source": [
    "from cluster import to_sparse_upper_chunked\n",
    "\n",
    "sparse_dist_mat = to_sparse_upper_chunked(\n",
    "    dist_mat, chunk_size=500, save_path=\"sparse_dist_mat.npz\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "sparse_dist_mat = sp.load_npz(\"output/0.2/sparse_dist_mat.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_words(info_df: pd.DataFrame, align_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Efficiently extracts corresponding words from `align_df` based on `info_df` filenames.\n",
    "\n",
    "    Args:\n",
    "        info_df (pd.DataFrame): DataFrame containing `filename` column with \"file_wordID\".\n",
    "        align_df (pd.DataFrame): DataFrame containing `filename`, `word_id`, and `text`.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of corresponding words or \"_\" if no match is found.\n",
    "    \"\"\"\n",
    "    if \"word_id\" not in info_df:\n",
    "        split_cols = info_df[\"filename\"].str.split(\"_\", expand=True)\n",
    "        info_df[[\"filename\", \"word_id\"]] = split_cols\n",
    "        info_df[\"word_id\"] = info_df[\"word_id\"].astype(int)\n",
    "    merged_df = info_df.merge(align_df, on=[\"filename\", \"word_id\"], how=\"left\")\n",
    "\n",
    "    merged_df[\"text\"] = merged_df[\"text\"].fillna(\"_\")\n",
    "    return merged_df[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import editdistance\n",
    "import statistics\n",
    "\n",
    "\n",
    "def print_clusters(word_clusters, print_pure=False, print_inpure=True):\n",
    "    for i, clust in enumerate(word_clusters):\n",
    "        if len(clust) > 1:\n",
    "            clust_dist = []\n",
    "\n",
    "            for p, q in itertools.combinations(clust, 2):\n",
    "                dist = editdistance.eval(p, q)\n",
    "                clust_dist.append(dist)\n",
    "\n",
    "            if any(dist > 0 for dist in clust_dist) and print_inpure or print_pure:\n",
    "                print(f\"Cluster {i}: {statistics.mean(clust_dist)}\")\n",
    "                words = [j for j in clust]\n",
    "                print(\", \".join(words))\n",
    "                print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim_mat(dist_mat):\n",
    "    dist_mat = dist_mat.tocsr()\n",
    "\n",
    "    # Convert distances to similarities for nonzero elements\n",
    "    max_dist = dist_mat.data.max()\n",
    "    similarity_matrix = dist_mat.copy()\n",
    "    similarity_matrix.data = max_dist - similarity_matrix.data\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "sim_mat = get_sim_mat(sparse_dist_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 13967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<COOrdinate sparse matrix of dtype 'float32'\n",
      "\twith 15727680 stored elements and shape (63136, 63136)>\n",
      "  Coords\tValues\n",
      "  (0, 1)\t1.0\n",
      "  (0, 2)\t1.0\n",
      "  (0, 3)\t1.0\n",
      "  (0, 4)\t1.0\n",
      "  (0, 5)\t1.0\n",
      "  (0, 6)\t1.0\n",
      "  (0, 7)\t1.0\n",
      "  (0, 8)\t1.0\n",
      "  (0, 9)\t0.875\n",
      "  (0, 10)\t1.0\n",
      "  (0, 11)\t1.0\n",
      "  (0, 12)\t0.875\n",
      "  (0, 13)\t1.0\n",
      "  (0, 14)\t1.0\n",
      "  (0, 15)\t1.0\n",
      "  (0, 16)\t1.0\n",
      "  (0, 17)\t1.0\n",
      "  (0, 18)\t1.0\n",
      "  (0, 19)\t0.8571428656578064\n",
      "  (0, 20)\t0.875\n",
      "  (0, 21)\t1.0\n",
      "  (0, 22)\t0.875\n",
      "  (0, 23)\t1.0\n",
      "  (0, 24)\t1.0\n",
      "  (0, 25)\t1.0\n",
      "  :\t:\n",
      "  (63128, 132)\t0.0\n",
      "  (63128, 133)\t0.0\n",
      "  (63128, 134)\t0.0\n",
      "  (63128, 135)\t0.0\n",
      "  (63129, 130)\t0.0\n",
      "  (63129, 131)\t0.0\n",
      "  (63129, 132)\t0.0\n",
      "  (63129, 133)\t0.0\n",
      "  (63129, 134)\t0.0\n",
      "  (63129, 135)\t0.0\n",
      "  (63130, 131)\t0.0\n",
      "  (63130, 132)\t0.0\n",
      "  (63130, 133)\t0.0\n",
      "  (63130, 134)\t0.0\n",
      "  (63130, 135)\t0.0\n",
      "  (63131, 132)\t0.0\n",
      "  (63131, 133)\t0.0\n",
      "  (63131, 134)\t0.0\n",
      "  (63131, 135)\t0.0\n",
      "  (63132, 133)\t0.0\n",
      "  (63132, 134)\t0.0\n",
      "  (63132, 135)\t0.0\n",
      "  (63133, 134)\t0.0\n",
      "  (63133, 135)\t0.0\n",
      "  (63134, 135)\t0.0\n"
     ]
    }
   ],
   "source": [
    "print(sparse_dist_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
