Timer unit: 1e-09 s

Total time: 0.091343 s
File: /Users/daneladendorff/Desktop/adendorffy/acoustic-units/dist.py
Function: get_features_and_filenames at line 38

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    38                                           @profile
    39                                           def get_features_and_filenames(sorted_paths):
    40         1       1000.0   1000.0      0.0      filenames = []
    41         1          0.0      0.0      0.0      features = []
    42      1001    8422000.0   8413.6      9.2      for path in tqdm(sorted_paths, desc="Appending Features"):
    43      1000    2046000.0   2046.0      2.2          filenames.append(path.stem)
    44      1000   80743000.0  80743.0     88.4          feature = np.load(path)
    45      1000     130000.0    130.0      0.1          features.append(feature)
    46         1       1000.0   1000.0      0.0      return features, filenames

Total time: 22.5332 s
File: /Users/daneladendorff/Desktop/adendorffy/acoustic-units/dist.py
Function: main at line 49

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    49                                           @profile
    50                                           def main():
    51                                               # Process chunks
    52         1       1000.0   1000.0      0.0      gamma = 0.1
    53         1 1270299000.0    1e+09      5.6      paths = list(Path(f"features/{gamma}").rglob("*.npy"))
    54                                           
    55         1   91372000.0    9e+07      0.4      sorted_paths = sorted(paths, key=lambda x: int(x.stem.split("_")[-1]))
    56         1     209000.0 209000.0      0.0      sorted_paths = sorted_paths[0:1000]
    57         1       1000.0   1000.0      0.0      sample_size = len(sorted_paths)
    58                                           
    59         1   91936000.0    9e+07      0.4      features, filenames = get_features_and_filenames(sorted_paths)
    60                                           
    61         1       2000.0   2000.0      0.0      chunk_limit = 5000000
    62         1       2000.0   2000.0      0.0      num_pairs = sample_size * (sample_size - 1) // 2
    63         1       1000.0   1000.0      0.0      num_chunks = (num_pairs + chunk_limit - 1) // chunk_limit
    64                                           
    65         1      10000.0  10000.0      0.0      print(f"num_pairs: {num_pairs}")
    66         1       2000.0   2000.0      0.0      print(f"num_chunks: {num_chunks}")
    67         1       2000.0   2000.0      0.0      print(f"num_samples: {sample_size}")
    68                                           
    69                                               # Preallocate sparse matrix in LIL format (efficient for incremental additions)
    70         1     365000.0 365000.0      0.0      dist_sparse = sp.lil_matrix((sample_size, sample_size), dtype=np.float32)
    71                                           
    72                                               # Process Chunks Efficiently
    73         3  190473000.0    6e+07      0.8      for chunk in tqdm(
    74         1       3000.0   3000.0      0.0          get_batch_of_paths(sample_size, chunk_limit=chunk_limit),
    75         1          0.0      0.0      0.0          total=num_chunks,
    76         1          0.0      0.0      0.0          desc="Processing Chunks",
    77         1          0.0      0.0      0.0          unit="chunk",
    78                                               ):
    79                                                   # Avoid unnecessary dictionary wrapping
    80    499501  167954000.0    336.2      0.7          chunk_units = [((i, j), (features[i], features[j])) for i, j in chunk]
    81                                           
    82         2   20912000.0    1e+07      0.1          with Pool(6) as pool:
    83    499501        2e+10  36191.7     80.2              for i, j, dist in pool.imap_unordered(cal_dist_per_pair, chunk_units):
    84    499500 1287751000.0   2578.1      5.7                  dist_sparse[i, j] = dist  # Fill the sparse matrix
    85    499500 1179409000.0   2361.2      5.2                  dist_sparse[j, i] = dist  # Symmetric distance
    86                                           
    87                                               # Convert to a compressed sparse format for efficient storage
    88         1   37944000.0    4e+07      0.2      dist_sparse = dist_sparse.tocoo()
    89         1  116696000.0    1e+08      0.5      np.savez_compressed("output/test/sparse_dist_mat.npz", dist_sparse)

  0.09 seconds - /Users/daneladendorff/Desktop/adendorffy/acoustic-units/dist.py:38 - get_features_and_filenames
 22.53 seconds - /Users/daneladendorff/Desktop/adendorffy/acoustic-units/dist.py:49 - main
